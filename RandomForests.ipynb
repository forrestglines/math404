{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In addition to randomizing the variables it splits on, I also made my random forest choose a random data set to build each tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def giniImpurity(y,classes):\n",
    "    fk = np.array([(y == k).sum()/(1.*len(y)) for k in classes])\n",
    "    return 1 - sum(fk**2.)\n",
    "\n",
    "def split(D,y,p,x):\n",
    "    if type(x) == float or type(x) == np.float64:\n",
    "        D1 = D[D.ix[:,p] <= x]\n",
    "        y1 = y[D.ix[:,p] <= x]\n",
    "        D2 = D[D.ix[:,p] > x]\n",
    "        y2 = y[D.ix[:,p] > x]\n",
    "    else:\n",
    "        D1 = D[D.ix[:,p] == x]\n",
    "        y1 = y[D.ix[:,p] == x]\n",
    "        D2 = D[D.ix[:,p] != x]\n",
    "        y2 = y[D.ix[:,p] != x]\n",
    "    return D1,y1,D2,y2\n",
    "\n",
    "def infoGain(D,y,D1,y1,D2,y2,classes):\n",
    "    return (giniImpurity(y,classes) - len(y1)/(1.*len(D))*giniImpurity(y1,classes)\n",
    "                             - len(y2)/(1.*len(D))*giniImpurity(y2,classes))\n",
    "\n",
    "def optimalSplit(D,y,classes,avail_vars):\n",
    "    best_x = None\n",
    "    best_p = None\n",
    "    max_I = -np.infty\n",
    "    for p in avail_vars:\n",
    "        vals = np.unique(D.ix[:,p])\n",
    "\n",
    "        for x in vals:\n",
    "            D1,y1,D2,y2 = split(D,y,p,x)\n",
    "            I = infoGain(D,y,D1,y1,D2,y2,classes)\n",
    "            if I > max_I:\n",
    "                best_x = x\n",
    "                best_p = p\n",
    "                max_I = I\n",
    "    return best_p,best_x\n",
    "\n",
    "class ForestNode:\n",
    "    def __init__(self,D,y,classes,max_dep,num_vars,tol,cur_dep=1,avail_vars=None):\n",
    "        self.D = None\n",
    "        avail = avail_vars\n",
    "        if avail == None:\n",
    "            avail = range(D.shape[1])\n",
    "        self.avail_vars = []\n",
    "        for p in avail:\n",
    "            if len(np.unique(D.ix[:,p])) > 1:\n",
    "                self.avail_vars.append(p)\n",
    "        self.avail_vars = np.array(self.avail_vars)\n",
    "        \n",
    "        \n",
    "        self.tol = tol\n",
    "        self.cur_dep = cur_dep\n",
    "        self.max_dep = max_dep\n",
    "        \n",
    "        self.G = giniImpurity(y,classes)\n",
    "        \n",
    "        if self.G < self.tol or self.cur_dep == self.max_dep or len(self.avail_vars) < num_vars:\n",
    "            self.label = mode(y).mode[0][0]\n",
    "            self.leftChild = None\n",
    "            self.rightChild = None\n",
    "            self.p = None\n",
    "            self.x = None\n",
    "            \n",
    "        else:\n",
    "            self.label = None\n",
    "            split_vars = np.random.permutation(self.avail_vars)[:num_vars]\n",
    "            \n",
    "            p,x = optimalSplit(D,y,classes,split_vars)\n",
    "            \"\"\"\n",
    "            if p == None:\n",
    "                self.label = mode(y).mode[0][0]\n",
    "                self.leftChild = None\n",
    "                self.rightChild = None\n",
    "                self.p = None\n",
    "                self.x = None\n",
    "            else:\\\n",
    "            \"\"\"\n",
    "            D1,y1,D2,y2 = split(D,y,p,x)\n",
    "            self.leftChild = ForestNode(D1,y1,classes,max_dep,num_vars,tol,cur_dep+1,avail_vars = self.avail_vars)\n",
    "            self.rightChild = ForestNode(D2,y2,classes,max_dep,num_vars,tol,cur_dep+1,avail_vars = self.avail_vars)\n",
    "            self.p = p\n",
    "            self.x = x\n",
    "    def printTree(self):\n",
    "        if self.p != None:\n",
    "            print \" \"*(self.cur_dep-1),self.p,self.x\n",
    "            self.leftChild.printTree()\n",
    "            self.rightChild.printTree()\n",
    "        else:\n",
    "            print \" \"*(self.cur_dep-1),self.label\n",
    "    def classify(self,d):\n",
    "        if self.label != None:\n",
    "            return self.label\n",
    "        else:\n",
    "            if type(self.x) == float or type(self.x) == np.float64:\n",
    "                if d[self.p] <= self.x:\n",
    "                    return self.leftChild.classify(d)\n",
    "                else:\n",
    "                    return self.rightChild.classify(d)\n",
    "            else:\n",
    "                if d[self.p] == self.x:\n",
    "                    return self.leftChild.classify(d)\n",
    "                else:\n",
    "                    return self.rightChild.classify(d)\n",
    "                \n",
    "class Forest:\n",
    "    def __init__(self,D,y,classes, max_dep,tol, num_trees,num_datums,num_vars):\n",
    "        \"\"\"\n",
    "        Train a collection of random trees.\n",
    "        Parameters\n",
    "        ----------\n",
    "        data : ndarray of shape (n,k)\n",
    "        Each row is an observation.\n",
    "        targets : ndarray of shape (K,)\n",
    "        The possible labels or classes.\n",
    "        Gini : float\n",
    "        The Gini impurity tolerance\n",
    "        max_depth : int\n",
    "        The maximum depth for the the trees\n",
    "        num_trees : int\n",
    "        The number of trees in the forest.\n",
    "        num_vars : int\n",
    "        The number of variables randomly selected at each node.\n",
    "        \"\"\"\n",
    "        self.trees = []\n",
    "        for i in xrange(num_trees):\n",
    "            print \"Building tree \",i\n",
    "            sort = np.argsort(np.random.rand(D.shape[0]))[:num_datums]\n",
    "            tree = ForestNode(D.ix[sort],y.ix[sort],classes,max_dep,num_vars,tol)\n",
    "            self.trees.append(tree)\n",
    "            \n",
    "    def classify(self,d):\n",
    "        votes = np.array([tree.classify(d) for tree in self.trees])\n",
    "        return mode(votes).mode[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allData = pd.read_csv(\"titanic4real.csv\")\n",
    "train = allData[:int(len(allData)*.8)]\n",
    "test = allData[int(len(allData)*.8):]\n",
    "\n",
    "train = train.fillna(0)\n",
    "trainSurvive = train[[\"Survived\"]]\n",
    "train = train[[\"Pclass\",\"Sex\",\"Age\"]]\n",
    "train = train.replace({'male': 1, 'female': 0})\n",
    "\n",
    "test = test.fillna(0)\n",
    "testSurvive = test[[\"Survived\"]]\n",
    "test = test[[\"Pclass\",\"Sex\",\"Age\"]]\n",
    "test = test.replace({'male': 1, 'female': 0})\n",
    "\n",
    "classes = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-c:42: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building tree  1\n",
      "Building tree  2\n",
      "Building tree  3\n",
      "Building tree  4\n",
      "Building tree  5\n",
      "Building tree  6\n",
      "Building tree  7\n",
      "Building tree  8\n",
      "Building tree  9\n",
      "Building tree  10\n",
      "Building tree  11\n",
      "Building tree  12\n",
      "Building tree  13\n",
      "Building tree  14\n",
      "Building tree  15\n",
      "Building tree  16\n",
      "Building tree  17\n",
      "Building tree  18\n",
      "Building tree  19\n",
      "Building tree  20\n",
      "Building tree  21\n",
      "Building tree  22\n",
      "Building tree  23\n",
      "Building tree  24\n",
      "Building tree  25\n",
      "Building tree  26\n",
      "Building tree  27\n",
      "Building tree  28\n",
      "Building tree  29\n",
      "Building tree  30\n",
      "Building tree  31\n",
      "Building tree  32\n",
      "Building tree  33\n",
      "Building tree  34\n",
      "Building tree  35\n",
      "Building tree  36\n",
      "Building tree  37\n",
      "Building tree  38\n",
      "Building tree  39\n",
      "Building tree  40\n",
      "Building tree  41\n",
      "Building tree  42\n",
      "Building tree  43\n",
      "Building tree  44\n",
      "Building tree  45\n",
      "Building tree  46\n",
      "Building tree  47\n",
      "Building tree  48\n",
      "Building tree  49\n",
      "Building tree  50\n",
      "Building tree  51\n",
      "Building tree  52\n",
      "Building tree  53\n",
      "Building tree  54\n",
      "Building tree  55\n",
      "Building tree  56\n",
      "Building tree  57\n",
      "Building tree  58\n",
      "Building tree  59\n",
      "Building tree  60\n",
      "Building tree  61\n",
      "Building tree  62\n",
      "Building tree  63\n",
      "Building tree  64\n",
      "Building tree  65\n",
      "Building tree  66\n",
      "Building tree  67\n",
      "Building tree  68\n",
      "Building tree  69\n",
      "Building tree  70\n",
      "Building tree  71\n",
      "Building tree  72\n",
      "Building tree  73\n",
      "Building tree  74\n",
      "Building tree  75\n",
      "Building tree  76\n",
      "Building tree  77\n",
      "Building tree  78\n",
      "Building tree  79\n",
      "Building tree  80\n",
      "Building tree  81\n",
      "Building tree  82\n",
      "Building tree  83\n",
      "Building tree  84\n",
      "Building tree  85\n",
      "Building tree  86\n",
      "Building tree  87\n",
      "Building tree  88\n",
      "Building tree  89\n",
      "Building tree  90\n",
      "Building tree  91\n",
      "Building tree  92\n",
      "Building tree  93\n",
      "Building tree  94\n",
      "Building tree  95\n",
      "Building tree  96\n",
      "Building tree  97\n",
      "Building tree  98\n",
      "Building tree  99\n"
     ]
    }
   ],
   "source": [
    "forest = Forest(train,trainSurvive,classes,10,.1,100,50,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labs = test.apply(forest.classify,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797709923664\n"
     ]
    }
   ],
   "source": [
    "labs.to_frame()\n",
    "lv = labs.values\n",
    "tv = testSurvive.values.reshape(lv.shape[0])\n",
    "print (tv == lv).sum()/(1.*len(tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random forests really didn't do much better than regular classification trees"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python2",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
